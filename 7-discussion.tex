

We would be remiss not to mention some closely related studies on multiple testing in high-dimensions, and the interesting theoretical results derived therein.

Performance limits of statistical procedures in the additive error model \eqref{eq:model-additive} have been actively studied in recent years.
Specifically, when the approximate support recovery risk \eqref{eq:risk-approximate} is used as the criterion, the asymptotic optimality of the Benjamini-Hochberg procedure \cite{benjamini1995controlling}, and the Cand\'es-Barber procedure \cite{barber2015controlling} was established by \citet*{arias2017distribution} under independent additive errors and one-sided alternatives.
% \citet{rabinovich2017optimal} further established the rate-optimality of both procedures under the same regime.

In terms of the more stringent exact support recovery probability \eqref{eq:risk-prob}, several well-known FWER-controlling procedures --- including Bonferroni's procedure --- have been shown to be optimal in the additive error model under one-sided alternatives \cite{gao2018fundamental}.
Optimality results were also obtained for a specific procedure under the expected Hamming loss ($\E[\widehat{S}\triangle S]$) in \cite{butucea2018variable},
% Theoretical limits in the Gaussian additive error model \eqref{eq:model-additive} have been recently studied in \cite{butucea2018variable} under the Hamming loss, $\E[\widehat{S}\triangle S]$.
where the asymptotic analyses focused exclusively on the two-sided alternatives.
% , while the former focused exclusively on the one-sided alternatives. 
% falling just short of an explicit comparison between the two.
% , due in part to slightly different goals of the projects. 
% Our discussions above also applied to the Hamming loss.

There is a wealth of literature on the so-called sparsistency (i.e., $\P[\widehat{S} = S]\to 1$ as $p\to\infty$) problem in the regression context. 
We refer readers to the recent book by \citet{wainwright2019high} (and in particular, the bibliographical sections of Chapters 7 and 15) for a comprehensive review.
We only mention two additional papers by \citet{ji2012ups} and \citet{jin2014optimality} which derived minimax optimality results under the Hamming loss in this context.

The asymptotic optimality of the Bonferroni and Benjamini-Hochberg procedures 
% in the Gaussian scale mixture model 
was analyzed under decision theoretic frameworks in \cite{genovese2002operating, bogdan2011asymptotic, neuvial2012false}, with main focus on location/scale models. 
In particular, these papers show that the statistical risks of the practical procedures come close to that of the oracle procedures under suitable asymptotic regimes.
Strategies for dealing with multiple testing under general distributional assumptions can be found in, e.g., \cite{efron2004large, storey2007optimal, sun2007oracle}, where the non-nulls are assumed to follow a common distribution; the two-sided alternative in the additive error model was featured as the primary example in \cite{sun2007oracle}.
Although weighted sums of false discovery and non-discovery have been studied in the literature, asymmetric statistical risks such as \eqref{eq:risk-exact-approx} and \eqref{eq:risk-approx-exact} are new.
The high-dimensional chi-square model \eqref{eq:model-chisq} also seemed to have received little attention.
While the sparse signal detection problem in the chi-square model has been studied \cite{donoho2004higher}, support recovery problems, to the best of our knowledge, remain unexplored until now.
% In particular, \citet{sun2007oracle} studied likelihood thresholding procedure % ; their proposed likelihood ratio thresholding procedure requires consistent estimation of the non-null distributions and the mixture proportions.

Finally, asymptotic power approximations of association tests on contingency tables can be found in, e.g., \citet{ferguson2017course} or other texts on asymptotic statistics.
A companion paper to the current work analyzes asymptotic equivalences of several additional common association tests, and implements second order power approximations in a software tool \cite{gao2019upass}. 
The software also facilitates visualization and forensics of reported findings in genetic association studies.

\medskip
% \subsection{Optimality of thresholding procedures}

Although it is intuitively appealing to consider only data-thresholding procedures in multiple testing problems, such procedures are not always optimal.
Recently, \citet{chen2018scan} showed that thresholding procedures are in fact sub-optimal in the additive models \eqref{eq:model-additive} when errors have heavy (regularly-varying) tails. 
\citet{gao2018fundamental} characterized the conditions under which thresholding procedures are optimal in the exact support recovery problem.
The optimality of data-thresholding procedures in terms of other statistical risks is an open problem that invites a dedicated investigation in a future study. 
% We content ourselves with making optimality statements concerning only thresholding procedures in the current work.

\medskip

Keen readers must have noticed the curious asymmetry in Relation \eqref{eq:failure-recovery-implies-risk-1} when we discussed the relationship between the exact support recovery risk \eqref{eq:risk-exact} and the probability of exact support recovery \eqref{eq:risk-prob}.


%The converse of \eqref{eq:failure-recovery-implies-risk-1} is not true.
While a trivial procedure that never rejects and a procedure that always rejects both have $\mathrm{risk}^{\mathrm{E}}$ equal to 1, the converse is not true.
For example, it is possible that a procedure selects the true index set $S$ with probability $1/2$, but makes one false inclusion \emph{and} one false omission simultaneously the other half of the time. 
In this case the procedure will have 
$$\mathrm{risk}^{\mathrm{E}} = 1, \quad \text{and} \quad \P[\widehat{S}=S] = 1/2,$$
showing that the converse of Relation \eqref{eq:failure-recovery-implies-risk-1} is in fact false.

The same argument applies to $\mathrm{risk}^{\mathrm{A}}$:
a procedure may select the true index set $S$ with probability $1/2$, but makes enough false inclusions and omissions other half of the time, so that $\mathrm{risk}^{\mathrm{A}}$ is equal to one.
Recently, \citet{arias2017distribution} commented (in their Remark 2) that a procedure with approximate support recovery risk equal to or exceeding 1 is useless --- an opinion with which we beg to differ, in light of this artificial but legitimate example.
% --- although the class of methods with risks equal to or exceeding 1 certainly contains the trivial procedures that we mentioned.

\medskip

The current work focused only on the idealized models \eqref{eq:model-chisq} and \eqref{eq:model-additive} where statistics are \emph{independent}.
In practice, independence is the exception rather than the rule. 
Support recovery problems under dependent observations should be vigorously explored.
There have been some efforts in this direction.
In particular, the boundary for the exact support recovery problem in the additive error model \eqref{eq:model-additive} was shown to hold even under severe dependence and general distributional assumptions \cite{gao2018fundamental}.
% \cite{ji2012ups} 
We conjecture that other phase transitions also continue to hold, under classes of dependence structures that are ``not too different from independence''.
As an example, in the GWAS application, dependence among the genetic markers at different locations (known as linkage disequilibrium) decay as a function of their physical distances on the genome \cite{bush2012genome}, resulting in locally dependent test statistics.
It would be of great interest to extend the current theory to cover important dependence structures that arise in such applications.


